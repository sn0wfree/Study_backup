{
    "collab_server" : "",
    "contents" : "---\ntitle: 'BST169: Course Work Project answer'\nauthor: \"sn0wfree\"\ndate: \"11/10/2016\"\noutput: \n  pdf_document: \n    latex_engine: xelatex\n    number_sections: yes\n    toc: yes\n---\n\n#BST169: Course Work Project\n\n\n\n\n## Question 1:\n\n1. Consider  the model:\n\n\\centerline{$y_i = \\beta_0 +\\beta_1*x_{1,i} +\\beta_2*x_{2,i} +\\epsilon_i$   (1)}\n\n\n\nWhat is the requirement for $\\epsilon_i$ such that the following test statstics will\nbe valid to test H0: $\\beta_1 + \\beta_2 =1$? \n\n + $W=N*(SSR_{R} - SSR_{U})/SSR_{U}$  (Wald).\n + $LM = N*(SSR_{R} - SSR_{U})/SSR_{R}$ (Lagrange Multiplier),\n + $LR = N* ln(SSR_{R}/SSR_{U})$ (Likelihood Ratio)\n\nwhere $SSR_{R}$ is the sum of squared residuals obtained from the restricted model, \nwhile $SSR_{R}$ is from the unrestricted model.\n\n### ansewer\n\n\\centerline{$\\beta_1 + \\beta_2 =1$}\n<=>\n\n\\centerline{$R*\\beta =1$,} where $R=\\begin{bmatrix} 1 & 1 \\\\ \\end{bmatrix}$ $\\beta=\\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\end{bmatrix}$ \n\n1. Wald test\n\n\\centerline{H0: $\\beta_1 + \\beta_2 =1$}\n\n\\centerline{$y_{i}=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}+\\epsilon_{i}$}\n\\centerline{$y_{i}=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}+\\epsilon_{i}$ with $\\beta_{1}+\\beta_{2}=1$} \n\n0).\n\n\\leftline{$E(x_i\\epsilon_i)=0$, i = 1,2,...,N;}\n\\leftline{$E(||{x_i\\epsilon_i}||^{2+\\delta})<\\Delta<1$, for $\\exists\\delta>0$, k = 1,...,K + 1 and i = 1,2,...,N}\n\n1). chi-sq distribution\n\n\n\\centerline{$sqrt(N)(R*\\tilde{\\beta}-1)\\sim{N(0,RM_{N}^{-1}U_NM_{N}^{-1}R')}$,}\n where $\\tilde{\\beta}=(X'X)^{-1}X'y$\n\n\n\n\\centerline{$(1/N)(R\\tilde{\\beta}-1)(R(X'X)^{-1}\\tilde{U_N}(X'X)^{-1}R')^{-1}(R\\tilde{\\beta}-1)'\\sim{\\chi}^2$,}\nwhere $X=\\begin{bmatrix} X_1 & X_2 \\\\ \\end{bmatrix}$,\n      $\\tilde{\\beta}=\\begin{bmatrix} \\tilde{\\beta_1} \\\\ \\tilde{\\beta_2} \\\\ \\end{bmatrix}$\n      \n  \n\n2). homoscedasity\n\n\\centerline{$\\tilde{U_N}=(SSR_U/(N-K-1))X'X/N$}\n  \nis a symmetrical positive definite matrix computed from the constrained regresson such that $\\tilde{U_N}-U_N\\longrightarrow 0$\n\n2. Lagrange Multiplier\n        \n\\centerline{$y_{i}=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}+\\epsilon_{i}+\\lambda(\\beta_1+\\beta_2-1)$}\n=>\n\\centerline{$y=X\\beta+\\epsilon_{i}+\\lambda(R*\\beta-1)$}\n\n1). chi-sq distribution\n\n\\centerline{$(1/N)(R\\tilde{\\beta}-1)(R(X'X)^{-1}\\tilde{U_N}(X'X)^{-1}R')^{-1}(R\\tilde{\\beta}-1)'\\sim{\\chi}^2$}\n\n2). homoscedasity\n\n$\\tilde{U_N}$ is a symmetrical positive definite matrix computed from the constrained regresson such that $\\tilde{U_N}-U_N\\longrightarrow 0$\n\n3. Likelihood Ratio\n\n\\centerline{$\\epsilon_i\\sim i.i.d.N(0,\\sigma^2)$}\n\n\n\n## Question 2\n\n2. For the data set **pbp.csv**, can we use the **three test statistics** mentioned in the previous question to test H0 :  $\\beta_{1} + \\beta_{2} = 1$? Why? \nIf W and LM are not valid, how can one modify them for the test? \nWhat is your conclusion from the valid test?\n\nNo,the Wald test and LM test may invalid. Becaue there may have heteroscedasticity, the requirements of Wald and LM test(homoscedasity) is not satisfied. Thus, the exteral test--heteroscedasticity test should be used before proceduring the Wald and LM test. \n\nthere are two heteroscedasticity test: White test and Breusch-Pagan-Godfrey Test. But the White test is more general for the this linear regression model.\n\n~~~~~\n\nequ1:\\centerline{$y_i = \\beta_0 +\\beta_1*x_{1,i} +\\beta_2*x_{2,i} +\\epsilon_i$}\nequ2:\\centerline{$y_{i}-x_{2}=\\beta_{0}+\\beta_{1}(x_{1}-x_{2})+\\epsilon_{i}$}\n\n```{r heteroscedasticity:package}\npbp=read.csv(\"/Users/sn0wfree/Dropbox/PhD_1st_study/BST169_Econometrics/Crousework_Project/pbp.csv\")\n#head(pbp)\n#str(pbp)\n\nrequire(lmtest)\nequ1<-lm(y~x1 + x2,data=pbp)\nequ2<-lm((y-x2)~(x1-x2), data=pbp)\n#Breusch-Pagan-Godfrey Test\nbptest(equ1)\nbptest(equ2)\n#White test\nbptest(residuals(equ1)~x1+x2+x1*x2+x1^2+x2^2,data=pbp)\nbptest(residuals(equ2)~(x1-x2)+(x1-x2)^2,data=pbp)\n\n```\n\nFrom White test and Breusch-Pagan-Godfrey Test, the **equ1** results reject the NULL hypothesis: Homoscedasity, Which means the heteroscedasticity exist. And **equ2** do not reject the NULL hypothesis. thus there exist Homoscedasity\n\nOverall, Wald and LM test is invalid. The original eqution: equ1 exist the heteroscedasticity.\n\nSolutaion:\nUsing Weighted Least Squared method to estimated the targeted regression rather than OLS.\n\n\n## Question 3\n\n3. Generate $y_{i}$ from the following model,\n\n\\centerline{$y_i = \\beta_0 + \\beta_{1}*x_{1,i} +(1-\\beta_{1})*x_{2,i} +\\sqrt{x_{1,i}}*\\epsilon_{1}$   (2)}\n\nwhere $x_{1,i}$ follows chi-squared distribution with **2** degrees of freedom. \nGenerate $\\epsilon_{1}$ from student t distribution with 6 degrees of freedom and $x_{2,i}$~$U(0,10)$. Check whether Wald, LR and LM in Question 1 follow chi-squared distribution by Monte Carlo.(The R command: ks.test( ,’pchisq’,2) can be used.) \nIf W and LM are not valid, calculate the correct test statistics and also verify them by Monte Carlo. Please consider different sample sizes.\n\nIn text, $x_1\\sim\\chi^2(2)$ and,\nGenerate $x_2\\sim{U(0,10)}$ and $\\epsilon_i\\sim{T(6)}$.\n\nHere set the sample size with $10+loop$ and loop 10000 times. and the eqution 2 transform to\n\n\\centerline{$y_i = \\beta_0 + \\beta_{1}*x_{1,i} +\\beta_2*x_{2,i} +e_i$   (2.1)}\n\nwhere\n\n\\centerline{$\\beta_{2}=1-\\beta_{1}$}\n\\centerline{$e_i=\\sqrt{x_{1,i}}*\\epsilon_{1}$}\nAnd I assume that $\\beta_1 = 0.5$, $\\beta_0=24$, and given a fixed value set $x_1$\n\n\n\n\nfrom mc1.r mc2.r\n\nlecture Monte Carlo\n\nsample size; estimation:power of test\nks.test(x,\"pchisq\",2)\n\n```{r Monte Carlo}\nrequire(lmtest)\nrequire(MASS)\nrequire(stats)\n##boost up: translate programme language code into Byte-code.\nrequire(compiler)\nenableJIT(3)\n##boost up-end for continues\n#assumption part\n\nloop=100\n#Warning: the loop time cannot be larger any more;please forgive me, this all my Macbook fault. And the optimization of R is terrible.\n\nbeta_1=0.4\nbeta_0=1\nx1_store=rchisq(80+20, 2)\n#initial valueset\noriginal_N=10\nsignlevel=0.05\n\nW_count=rep(0,loop)\nLM_count=rep(0,loop)\nLR_count=rep(0,loop)\n\n#\n# for loop start:Monte Carlo\nfor(j in 1:loop){\nW=rep(0,loop)\nLM=rep(0,loop)\nLR=rep(0,loop)\nN=original_N+j\nfor (i in 1:loop){\n#generation part:data\nx1=rchisq(N, 2)\nx2=runif(N,0,10)\nepsilon=rt(N,6)\ny=beta_0+beta_1*x1+(1-beta_1)*x2+sqrt(x1)*epsilon\n#generation part:regression\nequ1<-lm(y~x1+x2)\nequ2<-lm((y-x2)~(x1-x2))\n#calculation\n##pre-cal:heteroscedasticity\nif (bptest(equ1)$p.value<signlevel){\n  equ1<-lm(y~x1+x2,weights=(1/x1^0.5))\n  equ2<-lm((y-x2)~(x1-x2),weights=(1/x1^0.5))\n}\n#calc SSR and Wald,LM, and LR\nSSRu=sum(residuals(equ1)^2)\nSSRr=sum(residuals(equ2)^2)\n\nW=N*((SSRr-SSRu)/(SSRu))\nLM=N*((SSRr-SSRu)/(SSRr))\nLR=N*(log(SSRr/SSRu))\n\n\n\nif(ks.test(W,'pchisq',2)$p.value>signlevel){W_count[j]=W_count[j]+1}\nif(ks.test(LM,'pchisq',2)$p.value>signlevel){LM_count[j]=LM_count[j]+1}\nif(ks.test(LR,'pchisq',2)$p.value>signlevel){LR_count[j]=LR_count[j]+1}\n}\n}\n\nplot(W_count/(original_N+1:(original_N+loop))^2)\nplot(LM_count/(original_N+1:(original_N+loop))^2)\nplot(LR_count/(original_N+1:(original_N+loop))^2)\n\n```\n\n\n\nif(ks.test(W,'pchisq',2)$p.value<signlevel){print (\"Wald do not follow chi-squre distribution\")}else print  (\"Wald do follow chi-squre distribution\")\nif(ks.test(LM,'pchisq',2)$p.value<signlevel){print (\"LM do not follow chi-squre distribution\")}else print  (\"LM do follow chi-squre distribution\")\nif(ks.test(LR,'pchisq',2)$p.value<signlevel){print (\"LR do not follow chi-squre distribution\")}else print  (\"LR do follow chi-squre distribution\")\n\nW[i]=N*((SSRr-SSRu)/(SSRu))\nLM[i]=N*((SSRr-SSRu)/(SSRr))\nLR[i]=N*(log(SSRr/SSRu))\n\n\n\n\n\n## Question 4\n\nCompare the size of different test statistics (frequencies of making Type 1 error) from Monte Carlo using 5% level of significance for different sample sizes. Explain the results.\n```{r}\nplot(W_count/(original_N+1:(original_N+loop))^2)\nplot(LM_count/(original_N+1:(original_N+loop))^2)\nplot(LR_count/(original_N+1:(original_N+loop))^2)\n```\n\n\n\n## Question 5\n\nFor the data set pbp.csv, suppose Equation (2) is the true model. Use proper bootstrapped errors from the true model to study whether different test statistics for H0 :  $\\beta_{1} + \\beta_{2} = 1$ in the previous questions follow chi-squared distribution. Explain your results.\n\n\n------------\nreject null, make type I error\n\n\nbootstrap, \n\nhomoscedacity\ntwo types of bootstrap\nrobust test\nbootstrap for $\\epsilon_{i}$\ndifferent performance\n\n\nt-distribution ^2 => F distribution\nsingle $\\beta$->t-test\n\n$y_{i}=\\beta_{0}+\\beta_{1}(x_{1}-x_{2})+\\theta x_{2}+\\epsilon_{i}$\n$H_0:\\theta=\\beta_{1}+\\beta_{2}$\nuse t test for $\\theta$ is as same with f-test with $\\beta_{1}$,$\\beta_{2}$ \n\n```{r Monte Carlo for t test}\nrequire(lmtest)\nrequire(MASS)\nrequire(stats)\n##boost up: translate programme language code into Byte-code.\nrequire(compiler)\nenableJIT(3)\n##boost up-end for continues\n#assumption part\n\nloop=50\n#Warning: the loop time cannot be larger any more;please forgive me, this all my Macbook fault. And the optimization of R is terrible.\n\n\n\n#initial valueset\noriginal_N=10\nsignlevel=0.05\n\ntheta_count=rep(0,loop)\n\n#\n# for loop start:Monte Carlo\nfor(j in 1:loop){\ntheta=rep(0,loop)\nN=original_N+j\nfor (i in 1:loop){\n#generation part:data\ns=sample(1:length(pbp$y),N,replace = 1)\nquestion5.y<-pbp$y[s]\nquestion5.x1<-pbp$x1[s]\nquestion5.x2<-pbp$x2[s]\nee=rnorm(N,mean=0,sd=sqrt(var(question5.y)))\n#epsilon=ee/sqrt(x1)\n#y=beta_0+beta_1*x1+(1-beta_1)*x2+sqrt(x1)*epsilon\n#generation part:regression\nquestion5.equ1<-lm(question5.y~question5.x1+question5.x2)\n#question5.equ2<-lm((question5.y-question5.x2)~(question5.x1-question5.x2))\n#calculation\n##pre-cal:heteroscedasticity\nif (bptest(question5.equ1)$p.value<signlevel){\n  question5.equ1<-lm(question5.y~question5.x1+question5.x2,weights=(1/question5.x1^2))\n  #question5.equ2<-lm((question5.y-question5.x2)~(question5.x1-question5.x2),weights=(1/question5.x1^0.5))\n}\n#calc \n\ntheta[i]=question5.equ1$coefficients[2]+question5.equ1$coefficients[3]\n\n}\nif(t.test(theta,rep(1,loop))$p.value<signlevel){theta_count[j]=theta_count[j]+1}\n}\n\nplot(theta_count/(N+1:(N+loop)^2))\n```\n",
    "created" : 1478992170545.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4292319664",
    "id" : "9D2ED94C",
    "lastKnownWriteTime" : 1485153108,
    "last_content_update" : 1485153108410,
    "path" : "~/Dropbox/PhD_1st_study/BST169_Econometrics/Crousework_Project/BST169Coursework project answer.Rmd",
    "project_path" : "BST169Coursework project answer.Rmd",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}